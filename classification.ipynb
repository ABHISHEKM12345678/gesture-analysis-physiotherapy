{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gWDgc07U1WW",
        "outputId": "ea2c0fb5-51ac-4d6b-f38c-e4375c5aa3a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature shape: (131, 150)\n",
            "Labels shape: (131,)\n",
            "Correct labels distribution: [34 97]\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           1.00        27\n",
            "   macro avg       1.00      1.00      1.00        27\n",
            "weighted avg       1.00      1.00      1.00        27\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 7  0]\n",
            " [ 0 20]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# --- 1. Load metadata ---\n",
        "csv_path = '/content/drive/MyDrive/DV project /Simplified/CombinedCSV/standing_metadata.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Filter for GestureLabel = 0\n",
        "gesture0_df = df[df['GestureLabel'] == 0].reset_index(drop=True)\n",
        "\n",
        "# --- 2. Load skeleton ---\n",
        "def load_skeleton(file_path):\n",
        "    \"\"\"\n",
        "    Load skeleton data from txt file.\n",
        "    Shape: (n_frames, n_joints, 3)\n",
        "    \"\"\"\n",
        "    data = np.loadtxt(file_path, delimiter=',')\n",
        "    n_joints = data.shape[1] // 3\n",
        "    data = data.reshape((-1, n_joints, 3))\n",
        "    return data\n",
        "\n",
        "# --- 3. Feature extraction ---\n",
        "def extract_features(data):\n",
        "    \"\"\"\n",
        "    Extract mean and std of each joint coordinate across frames.\n",
        "    Returns a 1D array of features.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    features.extend(np.mean(data, axis=0).flatten())  # mean x,y,z for each joint\n",
        "    features.extend(np.std(data, axis=0).flatten())   # std x,y,z for each joint\n",
        "    return np.array(features)\n",
        "\n",
        "# --- 4. Prepare dataset ---\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for idx, row in gesture0_df.iterrows():\n",
        "    file_path = '/content/drive/MyDrive/DV project /Simplified/Separated_Files_By_Position/standing/' + row['Filename']\n",
        "    if not os.path.exists(file_path):\n",
        "        continue\n",
        "    data = load_skeleton(file_path)\n",
        "    features = extract_features(data)\n",
        "    X.append(features)\n",
        "    y.append(1 if row['CorrectLabel'] == 1 else 0)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Feature shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n",
        "print(\"Correct labels distribution:\", np.bincount(y))\n",
        "\n",
        "# --- 5. Train/Test split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# --- 6. Random Forest classifier ---\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# --- 7. Predictions ---\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# --- 8. Evaluation ---\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo2tIQ3XtrgY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7l-jeygb168",
        "outputId": "37472080-f6fd-4484-d0b1-5876b0ee83ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== GestureLabel 0 ===\n",
            "Feature shape: (131, 150)\n",
            "Labels distribution: [34 97]\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           1.00        27\n",
            "   macro avg       1.00      1.00      1.00        27\n",
            "weighted avg       1.00      1.00      1.00        27\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 7  0]\n",
            " [ 0 20]]\n",
            "\n",
            "=== GestureLabel 1 ===\n",
            "Feature shape: (139, 150)\n",
            "Labels distribution: [ 25 114]\n",
            "Accuracy: 0.9285714285714286\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.92      1.00      0.96        23\n",
            "\n",
            "    accuracy                           0.93        28\n",
            "   macro avg       0.96      0.80      0.85        28\n",
            "weighted avg       0.93      0.93      0.92        28\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 3  2]\n",
            " [ 0 23]]\n",
            "\n",
            "=== GestureLabel 2 ===\n",
            "Feature shape: (116, 150)\n",
            "Labels distribution: [ 15 101]\n",
            "Accuracy: 0.9166666666666666\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.67      0.67         3\n",
            "           1       0.95      0.95      0.95        21\n",
            "\n",
            "    accuracy                           0.92        24\n",
            "   macro avg       0.81      0.81      0.81        24\n",
            "weighted avg       0.92      0.92      0.92        24\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 2  1]\n",
            " [ 1 20]]\n",
            "\n",
            "=== GestureLabel 3 ===\n",
            "Feature shape: (127, 150)\n",
            "Labels distribution: [32 95]\n",
            "Accuracy: 0.9615384615384616\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92         7\n",
            "           1       0.95      1.00      0.97        19\n",
            "\n",
            "    accuracy                           0.96        26\n",
            "   macro avg       0.97      0.93      0.95        26\n",
            "weighted avg       0.96      0.96      0.96        26\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 6  1]\n",
            " [ 0 19]]\n",
            "\n",
            "=== GestureLabel 4 ===\n",
            "Feature shape: (149, 150)\n",
            "Labels distribution: [ 30 119]\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         6\n",
            "           1       1.00      1.00      1.00        24\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 6  0]\n",
            " [ 0 24]]\n",
            "\n",
            "=== GestureLabel 5 ===\n",
            "Feature shape: (109, 150)\n",
            "Labels distribution: [  6 103]\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00        21\n",
            "\n",
            "    accuracy                           1.00        22\n",
            "   macro avg       1.00      1.00      1.00        22\n",
            "weighted avg       1.00      1.00      1.00        22\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 1  0]\n",
            " [ 0 21]]\n",
            "\n",
            "=== GestureLabel 6 ===\n",
            "Feature shape: (132, 150)\n",
            "Labels distribution: [ 23 109]\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00        22\n",
            "\n",
            "    accuracy                           1.00        27\n",
            "   macro avg       1.00      1.00      1.00        27\n",
            "weighted avg       1.00      1.00      1.00        27\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 5  0]\n",
            " [ 0 22]]\n",
            "\n",
            "=== GestureLabel 7 ===\n",
            "Feature shape: (147, 150)\n",
            "Labels distribution: [ 18 129]\n",
            "Accuracy: 0.9333333333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         4\n",
            "           1       0.93      1.00      0.96        26\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.96      0.75      0.81        30\n",
            "weighted avg       0.94      0.93      0.92        30\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 2  2]\n",
            " [ 0 26]]\n",
            "\n",
            "=== GestureLabel 8 ===\n",
            "Feature shape: (172, 150)\n",
            "Labels distribution: [ 17 155]\n",
            "Accuracy: 0.9142857142857143\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         3\n",
            "           1       0.91      1.00      0.96        32\n",
            "\n",
            "    accuracy                           0.91        35\n",
            "   macro avg       0.46      0.50      0.48        35\n",
            "weighted avg       0.84      0.91      0.87        35\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 0  3]\n",
            " [ 0 32]]\n",
            "\n",
            "All gestures processed. Models stored in 'results' dictionary.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# --- 1. Load metadata ---\n",
        "csv_path = '/content/drive/MyDrive/DV project /Simplified/CombinedCSV/standing_metadata.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# --- 2. Load skeleton function ---\n",
        "def load_skeleton(file_path):\n",
        "    \"\"\"\n",
        "    Load skeleton data from txt file.\n",
        "    Shape: (n_frames, n_joints, 3)\n",
        "    \"\"\"\n",
        "    data = np.loadtxt(file_path, delimiter=',')\n",
        "    n_joints = data.shape[1] // 3\n",
        "    data = data.reshape((-1, n_joints, 3))\n",
        "    return data\n",
        "\n",
        "# --- 3. Feature extraction ---\n",
        "def extract_features(data):\n",
        "    \"\"\"\n",
        "    Extract mean and std of each joint coordinate across frames.\n",
        "    Returns a 1D array of features.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    features.extend(np.mean(data, axis=0).flatten())  # mean x,y,z for each joint\n",
        "    features.extend(np.std(data, axis=0).flatten())   # std x,y,z for each joint\n",
        "    return np.array(features)\n",
        "\n",
        "# --- 4. Function to prepare data for a specific gesture ---\n",
        "def prepare_gesture_data(gesture_label):\n",
        "    gesture_df = df[df['GestureLabel'] == gesture_label].reset_index(drop=True)\n",
        "    X, y = [], []\n",
        "    for idx, row in gesture_df.iterrows():\n",
        "        file_path = '/content/drive/MyDrive/DV project /Simplified/Separated_Files_By_Position/standing/' + row['Filename']\n",
        "        if not os.path.exists(file_path):\n",
        "            continue\n",
        "        data = load_skeleton(file_path)\n",
        "        features = extract_features(data)\n",
        "        X.append(features)\n",
        "        y.append(1 if row['CorrectLabel'] == 1 else 0)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# --- 5. Train Random Forest for each gesture ---\n",
        "results = {}\n",
        "for gesture_label in range(0, 9):  # Gestures 0 to 8\n",
        "    print(f\"\\n=== GestureLabel {gesture_label} ===\")\n",
        "    X, y = prepare_gesture_data(gesture_label)\n",
        "    if len(y) == 0:\n",
        "        print(\"No data found for this gesture.\")\n",
        "        continue\n",
        "\n",
        "    print(\"Feature shape:\", X.shape)\n",
        "    print(\"Labels distribution:\", np.bincount(y))\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    results[gesture_label] = {\n",
        "        'model': clf,\n",
        "        'accuracy': acc,\n",
        "        'y_test': y_test,\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "\n",
        "print(\"\\nAll gestures processed. Models stored in 'results' dictionary.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1klilVWc6YY",
        "outputId": "2da9c445-0f51-4dca-b7d2-f89d5a85ab65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records used: 131\n",
            "Detected joints V = 25\n",
            "Epoch 01 | Train loss 0.4965 acc 0.7115 | Val loss 0.8369 acc 0.7407\n",
            "Saved best model. stgcn_gesture0_best.pth\n",
            "Epoch 02 | Train loss 0.3036 acc 0.8750 | Val loss 1.0495 acc 0.7407\n",
            "Epoch 03 | Train loss 0.2968 acc 0.8365 | Val loss 1.1705 acc 0.7407\n",
            "Epoch 04 | Train loss 0.2266 acc 0.9135 | Val loss 0.2498 acc 0.8889\n",
            "Saved best model. stgcn_gesture0_best.pth\n",
            "Epoch 05 | Train loss 0.2501 acc 0.9423 | Val loss 0.2270 acc 0.9259\n",
            "Saved best model. stgcn_gesture0_best.pth\n",
            "Epoch 06 | Train loss 0.2275 acc 0.9135 | Val loss 0.7763 acc 0.7778\n",
            "Epoch 07 | Train loss 0.2303 acc 0.9519 | Val loss 0.1554 acc 0.8889\n",
            "Epoch 08 | Train loss 0.2389 acc 0.8942 | Val loss 1.4048 acc 0.7407\n",
            "Epoch 09 | Train loss 0.1923 acc 0.9423 | Val loss 0.1783 acc 0.9259\n",
            "Epoch 10 | Train loss 0.1879 acc 0.9327 | Val loss 0.1580 acc 0.9259\n",
            "Epoch 11 | Train loss 0.1499 acc 0.9712 | Val loss 0.1304 acc 0.9259\n",
            "Epoch 12 | Train loss 0.1753 acc 0.9327 | Val loss 0.1216 acc 0.9259\n",
            "Epoch 13 | Train loss 0.1604 acc 0.9519 | Val loss 0.1040 acc 0.9259\n",
            "Epoch 14 | Train loss 0.1472 acc 0.9712 | Val loss 0.1055 acc 0.9259\n",
            "Epoch 15 | Train loss 0.1423 acc 0.9615 | Val loss 0.1013 acc 0.9630\n",
            "Saved best model. stgcn_gesture0_best.pth\n",
            "Epoch 16 | Train loss 0.1363 acc 0.9712 | Val loss 0.1361 acc 0.9630\n",
            "Epoch 17 | Train loss 0.0994 acc 0.9808 | Val loss 0.1153 acc 0.9630\n",
            "Epoch 18 | Train loss 0.1229 acc 0.9615 | Val loss 0.0855 acc 1.0000\n",
            "Saved best model. stgcn_gesture0_best.pth\n",
            "Epoch 19 | Train loss 0.1115 acc 0.9808 | Val loss 0.0897 acc 1.0000\n",
            "Epoch 20 | Train loss 0.1028 acc 0.9712 | Val loss 0.0911 acc 0.9630\n",
            "Epoch 21 | Train loss 0.1148 acc 0.9712 | Val loss 0.1002 acc 0.9630\n",
            "Epoch 22 | Train loss 0.1197 acc 0.9712 | Val loss 0.0835 acc 0.9630\n",
            "Epoch 23 | Train loss 0.1213 acc 0.9808 | Val loss 0.0845 acc 0.9630\n",
            "Epoch 24 | Train loss 0.1307 acc 0.9615 | Val loss 0.1205 acc 0.9630\n",
            "Epoch 25 | Train loss 0.1891 acc 0.9615 | Val loss 0.1459 acc 1.0000\n",
            "Epoch 26 | Train loss 0.1049 acc 0.9808 | Val loss 0.0804 acc 1.0000\n",
            "Epoch 27 | Train loss 0.1611 acc 0.9615 | Val loss 0.0952 acc 0.9259\n",
            "Epoch 28 | Train loss 0.1199 acc 0.9808 | Val loss 0.1370 acc 0.9259\n",
            "Epoch 29 | Train loss 0.1220 acc 0.9808 | Val loss 0.1036 acc 0.9259\n",
            "Epoch 30 | Train loss 0.1026 acc 0.9615 | Val loss 0.0694 acc 1.0000\n",
            "\n",
            "=== Final evaluation on test set ===\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           1.00        27\n",
            "   macro avg       1.00      1.00      1.00        27\n",
            "weighted avg       1.00      1.00      1.00        27\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 7  0]\n",
            " [ 0 20]]\n"
          ]
        }
      ],
      "source": [
        "# stgcn_pipeline.py  (run in Colab / local env)\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# ----------------------------\n",
        "# USER PARAMETERS - edit here\n",
        "# ----------------------------\n",
        "csv_path = '/content/drive/MyDrive/DV project /Simplified/CombinedCSV/standing_metadata.csv'\n",
        "data_folder = '/content/drive/MyDrive/DV project /Simplified/Separated_Files_By_Position/standing'\n",
        "gesture_label = 0         # which gesture to train on (0..8). Set to None to use all gestures.\n",
        "max_len = 150             # pad/truncate frames to this length\n",
        "batch_size = 16\n",
        "num_epochs = 30\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-4\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "save_model_path = 'stgcn_gesture{}_best.pth'.format(gesture_label if gesture_label is not None else 'all')\n",
        "# ----------------------------\n",
        "\n",
        "# ----------------------------\n",
        "# Graph definition (V joints)\n",
        "# ----------------------------\n",
        "# Use your skeleton connections (0-indexed). Adjust if your dataset joint ordering differs.\n",
        "connections = [\n",
        "    (0,1),(1,2),(2,3),      # Spine\n",
        "    (2,4),(4,5),(5,6),(6,7),# Left arm\n",
        "    (2,8),(8,9),(9,10),(10,11), # Right arm\n",
        "    (0,12),(12,13),(13,14),(14,15), # Left leg\n",
        "    (0,16),(16,17),(17,18),(18,19)  # Right leg\n",
        "]\n",
        "# We'll infer V from loading a sample file later.\n",
        "\n",
        "# ----------------------------\n",
        "# Utilities\n",
        "# ----------------------------\n",
        "def normalize_adjacency(A):\n",
        "    # symmetric normalization D^-1/2 A D^-1/2\n",
        "    D = np.sum(A, axis=1)\n",
        "    D_inv_sqrt = np.diag(1.0 / (np.sqrt(D) + 1e-6))\n",
        "    return D_inv_sqrt @ A @ D_inv_sqrt\n",
        "\n",
        "def build_adjacency_matrix(V, connections):\n",
        "    A = np.zeros((V, V), dtype=np.float32)\n",
        "    for i,j in connections:\n",
        "        if i < V and j < V:\n",
        "            A[i,j] = 1\n",
        "            A[j,i] = 1\n",
        "    # self connections\n",
        "    for v in range(V):\n",
        "        A[v,v] = 1.0\n",
        "    A = normalize_adjacency(A)\n",
        "    return A\n",
        "\n",
        "# ----------------------------\n",
        "# Dataset\n",
        "# ----------------------------\n",
        "class SkeletonDataset(Dataset):\n",
        "    def __init__(self, df, data_folder, gesture_label=None, max_len=150):\n",
        "        self.rows = df if gesture_label is None else df[df['GestureLabel'] == gesture_label]\n",
        "        self.rows = self.rows.reset_index(drop=True)\n",
        "        self.data_folder = data_folder\n",
        "        self.max_len = max_len\n",
        "        # pre-check one file to get V\n",
        "        sample_path = None\n",
        "        for i, r in self.rows.iterrows():\n",
        "            p = os.path.join(self.data_folder, r['Filename'])\n",
        "            if os.path.exists(p):\n",
        "                sample_path = p\n",
        "                break\n",
        "        if sample_path is None:\n",
        "            raise FileNotFoundError(\"No sample files found in dataset folder\")\n",
        "        sample = np.loadtxt(sample_path, delimiter=',')\n",
        "        self.V = sample.shape[1] // 3\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.rows)\n",
        "\n",
        "    def load_file(self, path):\n",
        "        data = np.loadtxt(path, delimiter=',')  # (T, V*3)\n",
        "        T = data.shape[0]\n",
        "        V = data.shape[1] // 3\n",
        "        data = data.reshape((T, V, 3))  # (T, V, 3)\n",
        "        return data.astype(np.float32)\n",
        "\n",
        "    def pad_truncate(self, x):\n",
        "        # x: (T, V, C=3) -> desired shape (max_len, V, 3)\n",
        "        T = x.shape[0]\n",
        "        if T >= self.max_len:\n",
        "            return x[:self.max_len]\n",
        "        else:\n",
        "            pad = np.zeros((self.max_len - T, x.shape[1], x.shape[2]), dtype=x.dtype)\n",
        "            return np.concatenate([x, pad], axis=0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.rows.loc[idx]\n",
        "        file_path = os.path.join(self.data_folder, row['Filename'])\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileNotFoundError(file_path)\n",
        "        x = self.load_file(file_path)  # (T, V, 3)\n",
        "        x = self.pad_truncate(x)       # (max_len, V, 3)\n",
        "        # transpose to (C, T, V)\n",
        "        x = np.transpose(x, (2, 0, 1)).copy()  # (3, T, V)\n",
        "        y = 1 if row['CorrectLabel'] == 1 else 0\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    xs, ys = zip(*batch)\n",
        "    xs = torch.stack(xs, dim=0)  # (N, C, T, V)\n",
        "    ys = torch.stack(ys).long()\n",
        "    return xs, ys\n",
        "\n",
        "# ----------------------------\n",
        "# Minimal ST-GCN building blocks\n",
        "# ----------------------------\n",
        "class GraphConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, A):\n",
        "        super().__init__()\n",
        "        # A is numpy adjacency (V,V) -> convert to torch\n",
        "        self.register_buffer('A', torch.tensor(A, dtype=torch.float32))\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        # x: (N, C, T, V)\n",
        "        # apply conv over channels then multiply by adjacency\n",
        "        # conv expects (N, C, T, V) -> conv over (C -> outC) with 1x1\n",
        "        x = self.conv(x)  # (N, outC, T, V)\n",
        "        # multiply in joint dimension: einsum\n",
        "        A = self.A  # (V,V)\n",
        "        x = torch.einsum('nctv,vw->nctw', x, A)\n",
        "        return x\n",
        "\n",
        "class TemporalConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=9, stride=1):\n",
        "        super().__init__()\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        self.tconv = nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size,1),\n",
        "                                padding=(padding,0), stride=(stride,1))\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        # x: (N, C, T, V) treat time as height\n",
        "        x = self.tconv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class STBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, A):\n",
        "        super().__init__()\n",
        "        self.gcn = GraphConv(in_channels, out_channels, A)\n",
        "        self.tcn = TemporalConv(out_channels, out_channels)\n",
        "        self.residual = nn.Identity() if in_channels == out_channels else nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        # x: (N, C, T, V)\n",
        "        y = self.gcn(x)\n",
        "        y = self.tcn(y)\n",
        "        res = self.residual(x)\n",
        "        return self.relu(y + res)\n",
        "\n",
        "# ----------------------------\n",
        "# ST-GCN Model\n",
        "# ----------------------------\n",
        "class STGCN(nn.Module):\n",
        "    def __init__(self, in_channels, A, num_class=2, layers_channels=[64,64,128,256]):\n",
        "        super().__init__()\n",
        "        self.register_buffer('A', torch.tensor(A, dtype=torch.float32))\n",
        "        layers = []\n",
        "        c = in_channels\n",
        "        for ch in layers_channels:\n",
        "            layers.append(STBlock(c, ch, A))\n",
        "            c = ch\n",
        "        self.st_blocks = nn.Sequential(*layers)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))  # average over time and joints\n",
        "        self.fc = nn.Linear(c, num_class)\n",
        "    def forward(self, x):\n",
        "        # x: (N, C, T, V)\n",
        "        x = self.st_blocks(x)\n",
        "        x = self.pool(x)  # (N, C, 1, 1)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# ----------------------------\n",
        "# Training / evaluation helpers\n",
        "# ----------------------------\n",
        "def train_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    preds = []\n",
        "    trues = []\n",
        "    for x,y in loader:\n",
        "        x = x.to(device)    # (N,C,T,V)\n",
        "        y = y.to(device)\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        preds += out.argmax(dim=1).detach().cpu().tolist()\n",
        "        trues += y.detach().cpu().tolist()\n",
        "    return np.mean(losses), accuracy_score(trues, preds)\n",
        "\n",
        "def eval_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    preds = []\n",
        "    trues = []\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            losses.append(loss.item())\n",
        "            preds += out.argmax(dim=1).detach().cpu().tolist()\n",
        "            trues += y.detach().cpu().tolist()\n",
        "    return np.mean(losses), accuracy_score(trues, preds), trues, preds\n",
        "\n",
        "# ----------------------------\n",
        "# Main: prepare data, model, train\n",
        "# ----------------------------\n",
        "def main():\n",
        "    # load metadata\n",
        "    df = pd.read_csv(csv_path)\n",
        "    if gesture_label is not None:\n",
        "        df_use = df[df['GestureLabel'] == gesture_label].reset_index(drop=True)\n",
        "    else:\n",
        "        df_use = df.copy().reset_index(drop=True)\n",
        "    print(\"Total records used:\", len(df_use))\n",
        "\n",
        "    # dataset and dataloaders\n",
        "    ds = SkeletonDataset(df_use, data_folder, gesture_label=gesture_label, max_len=max_len)\n",
        "    V = ds.V\n",
        "    print(\"Detected joints V =\", V)\n",
        "    # ensure connections are compatible - build adjacency based on detected V\n",
        "    A = build_adjacency_matrix(V, connections)\n",
        "\n",
        "    # split train/test stratified\n",
        "    labels = [1 if r['CorrectLabel'] == 1 else 0 for _, r in ds.rows.iterrows()]\n",
        "    labels = np.array(labels)\n",
        "    # simple split: 80/20 stratified\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    idx_all = np.arange(len(ds))\n",
        "    train_idx, test_idx = train_test_split(idx_all, test_size=0.2, random_state=42, stratify=labels)\n",
        "    train_rows = ds.rows.loc[train_idx].reset_index(drop=True)\n",
        "    test_rows = ds.rows.loc[test_idx].reset_index(drop=True)\n",
        "\n",
        "    train_ds = SkeletonDataset(train_rows, data_folder, gesture_label=None, max_len=max_len)\n",
        "    test_ds  = SkeletonDataset(test_rows, data_folder, gesture_label=None, max_len=max_len)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # model\n",
        "    model = STGCN(in_channels=3, A=A, num_class=2).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc, y_true, y_pred = eval_epoch(model, test_loader, criterion, device)\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch {epoch:02d} | Train loss {train_loss:.4f} acc {train_acc:.4f} | Val loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save({\n",
        "                'model_state': model.state_dict(),\n",
        "                'optimizer_state': optimizer.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'val_acc': val_acc\n",
        "            }, save_model_path)\n",
        "            print(\"Saved best model.\", save_model_path)\n",
        "\n",
        "    # final evaluation\n",
        "    print(\"\\n=== Final evaluation on test set ===\")\n",
        "    _, acc, y_true, y_pred = eval_epoch(model, test_loader, criterion, device)\n",
        "    print(\"Accuracy:\", acc)\n",
        "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfx0WfRNWcp7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}